import os
import requests
from bs4 import BeautifulSoup
import pymongo
import datetime
import time
import logging
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

def get_env_var():
    """
    .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    """
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    current_dir = os.path.dirname(os.path.abspath(__file__))
    env_path = os.path.join(current_dir, ".env")
    
    if os.path.exists(env_path):
        load_dotenv(env_path)
        logger.info(f".env loaded from {env_path}")
    else:
        logger.warning(f".env not found at {env_path}, trying system env vars")
        load_dotenv()

    mongo_uri = os.getenv("MONGO_URI")
    webhook_url = os.getenv("DISCORD_WEBHOOK")

    if not mongo_uri or not webhook_url:
        logger.error("MONGO_URI or DISCORD_WEBHOOK not found in environment variables.")
        return None

    return {
        "MONGO_URI": mongo_uri,
        "DISCORD_WEBHOOK": webhook_url
    }

def fetch_page(url, retries=3):
    """
    URL í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    for i in range(retries):
        try:
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            logger.warning(f"Attempt {i+1}/{retries} failed for {url}: {e}")
            time.sleep(2)
    
    logger.error(f"Failed to fetch {url} after {retries} attempts.")
    return None

def parse_contests():
    """
    K-CTF ì‚¬ì´íŠ¸ì—ì„œ ëŒ€íšŒ ëª©ë¡ ë° ìƒì„¸ ì •ë³´ íŒŒì‹±
    """
    base_url = "http://k-ctf.org"
    list_url = f"{base_url}/?status=registering"
    
    html = fetch_page(list_url)
    if not html:
        return []

    soup = BeautifulSoup(html, 'html.parser')
    contest_cards = soup.select("#contestWrapper-registering .contest-card-poster")
    
    contests = []
    
    logger.info(f"Found {len(contest_cards)} contests in list page.")

    for card in contest_cards:
        try:
            # ìƒì„¸ í˜ì´ì§€ ë§í¬ ì¶”ì¶œ
            onclick_attr = card.get("onclick")
            if not onclick_attr:
                continue
                
            # location.href='/contests/...' í˜•íƒœì—ì„œ URL ì¶”ì¶œ
            relative_link = onclick_attr.split("'")[1]
            detail_url = f"{base_url}{relative_link}"
            contest_id = relative_link.split("/")[-1] # URLì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì„ IDë¡œ ì‚¬ìš©

            # ìƒì„¸ í˜ì´ì§€ ì ‘ì†
            logger.info(f"Scraping detail page: {detail_url}")
            detail_html = fetch_page(detail_url)
            if not detail_html:
                continue
                
            detail_soup = BeautifulSoup(detail_html, 'html.parser')
            
            # ì •ë³´ ì¶”ì¶œ
            title_elem = detail_soup.select_one("h1.text-3xl.font-bold")
            title = title_elem.text.strip() if title_elem else "Unknown Title"
            
            # ì´ë¯¸ì§€ URL
            img_elem = detail_soup.select_one("img.object-cover")
            img_url = f"{base_url}{img_elem['src']}" if img_elem else ""
            
            # ê¸°ë³¸ ì •ë³´ (ì£¼ìµœ, ìš´ì˜, ë§í¬ ë“±)
            host = "Unknown"
            link = ""
            
            info_divs = detail_soup.select(".space-y-3.text-sm > div")
            for div in info_divs:
                text = div.text.strip()
                if "ì£¼ìµœ:" in text:
                    host = text.replace("ì£¼ìµœ:", "").strip()
                elif "ë§í¬:" in text:
                    link_tag = div.select_one("a")
                    if link_tag:
                        link = link_tag['href']

            # ì¼ì • ì •ë³´
            schedule_section = detail_soup.find("h2", string="ì¼ì •")
            schedule_text = ""
            apply_period = ""
            
            if schedule_section:
                schedule_container = schedule_section.parent
                
                # ëŒ€íšŒ ê¸°ê°„
                contest_period_elem = schedule_container.select_one(".border-l-4.border-blue-500 p.text-sm.text-gray-600")
                if contest_period_elem:
                    schedule_text = contest_period_elem.text.strip()
                
                # ì‹ ì²­ ê¸°ê°„
                apply_period_elem = schedule_container.select_one(".border-l-4.border-green-500 p.text-sm.text-gray-600")
                if apply_period_elem:
                    apply_period = apply_period_elem.text.strip()

            # ëŒ€íšŒ ì •ë³´ (ìœ í˜•, ìê²©, ìƒê¸ˆ)
            contest_type = ""
            qualification = ""
            prize = ""
            
            info_sidebar = detail_soup.find("h3", string="ëŒ€íšŒ ì •ë³´")
            if info_sidebar:
                sidebar_container = info_sidebar.parent
                sidebar_items = sidebar_container.select(".space-y-3.text-sm > div")
                
                for item in sidebar_items:
                    header = item.select_one("span.font-medium")
                    if not header:
                        continue
                    
                    header_text = header.text.strip()
                    content_p = item.select_one("p")
                    content = content_p.text.strip() if content_p else ""
                    
                    if "ëŒ€íšŒ ìœ í˜•:" in header_text:
                        contest_type = content
                    elif "ì°¸ê°€ ìê²©:" in header_text:
                        qualification = content
                    elif "ìƒê¸ˆ:" in header_text:
                        prize = content

            contest_data = {
                "_id": contest_id, # ê³ ìœ  ID
                "title": title,
                "url": detail_url,
                "image_url": img_url,
                "host": host,
                "link": link,
                "schedule": schedule_text,
                "apply_period": apply_period,
                "type": contest_type,
                "qualification": qualification,
                "prize": prize,
                "scraped_at": datetime.datetime.now()
            }
            
            contests.append(contest_data)
            time.sleep(1) # ì„œë²„ ë¶€í•˜ ë°©ì§€

        except Exception as e:
            logger.error(f"Error parsing contest card: {e}")
            continue
            
    return contests

def send_discord_webhook(contest, webhook_url):
    """
    ë””ìŠ¤ì½”ë“œ ì›¹í›… ì „ì†¡
    """
    embed = {
        "title": f"ğŸš© New CTF: {contest['title']}",
        "url": contest['url'],
        "color": 0xFF8C00, # Dark Orange
        "fields": [
            {"name": "ì£¼ìµœ", "value": contest['host'], "inline": True},
            {"name": "ìœ í˜•", "value": contest['type'], "inline": True},
            {"name": "ì°¸ê°€ ìê²©", "value": contest['qualification'][:1024], "inline": False}, # 1024ì ì œí•œ
            {"name": "ì‹ ì²­ ê¸°ê°„", "value": contest['apply_period'], "inline": False},
            {"name": "ëŒ€íšŒ ì¼ì •", "value": contest['schedule'], "inline": False},
            {"name": "ìƒê¸ˆ", "value": contest['prize'][:1024], "inline": False},
            {"name": "ê³µì‹ ë§í¬", "value": contest['link'] if contest['link'] else "N/A", "inline": False}
        ],
        "thumbnail": {"url": contest['image_url']},
        "footer": {"text": f"K-CTF Notification â€¢ {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}"}
    }

    payload = {
        "username": "K-CTF Bot",
        "avatar_url": "https://k-ctf.org/static/img/logo.png", # ë¡œê³ ê°€ ìˆë‹¤ë©´
        "embeds": [embed]
    }

    try:
        response = requests.post(webhook_url, json=payload)
        if response.status_code == 204:
            logger.info(f"Webhook sent for {contest['title']}")
        else:
            logger.error(f"Failed to send webhook: {response.status_code} {response.text}")
    except Exception as e:
        logger.error(f"Error sending webhook: {e}")

def sync_and_notify(current_contests, mongo_uri, webhook_url):
    """
    DB ë™ê¸°í™” ë° ì•Œë¦¼ ì „ì†¡
    """
    try:
        client = pymongo.MongoClient(mongo_uri)
        db = client.get_database('webhook')
        collection = db['KCTF_Latest']
        status_collection = db['KCTF_Status'] # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ìƒíƒœ ì €ì¥
        
        # í˜„ì¬ DBì— ìˆëŠ” ID ëª©ë¡
        stored_ids = [doc['_id'] for doc in collection.find({}, {"_id": 1})]
        current_ids = [c['_id'] for c in current_contests]
        
        # ì‹ ê·œ ëŒ€íšŒ (ì›¹ì—ëŠ” ìˆëŠ”ë° DBì—” ì—†ìŒ)
        new_contests = [c for c in current_contests if c['_id'] not in stored_ids]
        
        # ì‚­ì œëœ ëŒ€íšŒ (DBì—” ìˆëŠ”ë° ì›¹ì—” ì—†ìŒ - ì ‘ìˆ˜ ë§ˆê° ë“±)
        removed_ids = set(stored_ids) - set(current_ids)
        
        logger.info(f"Sync Status - New: {len(new_contests)}, Removed: {len(removed_ids)}")
        
        # 1. ì‹ ê·œ ëŒ€íšŒ ì²˜ë¦¬
        for contest in new_contests:
            # DB ì €ì¥
            collection.insert_one(contest)
            logger.info(f"Saved new contest to DB: {contest['title']}")
            
            # ì•Œë¦¼ ì „ì†¡
            send_discord_webhook(contest, webhook_url)
            time.sleep(1) # Rate limit ë°©ì§€
            
        # 2. ì‚­ì œëœ ëŒ€íšŒ ì²˜ë¦¬
        if removed_ids:
            result = collection.delete_many({"_id": {"$in": list(removed_ids)}})
            logger.info(f"Removed {result.deleted_count} contests from DB.")
            
        # 3. ì‹¤í–‰ ì‹œê°„ ì—…ë°ì´íŠ¸
        status_collection.update_one(
            {"_id": "scraper_status"},
            {"$set": {"last_run": datetime.datetime.now()}},
            upsert=True
        )
        logger.info("Updated last run time.")
            
    except Exception as e:
        logger.error(f"Database error: {e}")
    finally:
        client.close()

def check_last_run(mongo_uri):
    """
    ì˜¤ëŠ˜ ì´ë¯¸ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸
    """
    try:
        client = pymongo.MongoClient(mongo_uri)
        db = client.get_database('webhook')
        status_collection = db['KCTF_Status']
        
        doc = status_collection.find_one({"_id": "scraper_status"})
        if not doc:
            return False
            
        last_run = doc.get("last_run")
        if not last_run:
            return False
            
        # ì˜¤ëŠ˜ ë‚ ì§œì™€ ë¹„êµ
        if last_run.date() == datetime.datetime.now().date():
            return True
            
        return False
    except Exception as e:
        logger.error(f"Error checking last run: {e}")
        return False

if __name__ == "__main__":
    logger.info("Starting K-CTF Notification Script")
    
    env_vars = get_env_var()
    if env_vars:
        # ì˜¤ëŠ˜ ì´ë¯¸ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸
        if check_last_run(env_vars["MONGO_URI"]):
            logger.info(f"Already ran today ({datetime.datetime.now().strftime('%Y-%m-%d')}). Exiting.")
            exit(0)

        contests = parse_contests()
        if contests:
            sync_and_notify(contests, env_vars["MONGO_URI"], env_vars["DISCORD_WEBHOOK"])
        else:
            logger.info("No contests found or parsing failed.")
            
    logger.info("Script finished.")
