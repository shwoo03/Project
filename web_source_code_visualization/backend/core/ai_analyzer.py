import os
import groq
from typing import Dict, Any
from dotenv import load_dotenv

class AIAnalyzer:
    def __init__(self):
        # Force load .env from project root (3 levels up from backend/core/ai_analyzer.py)
        # backend/core/ai_analyzer.py -> backend/core -> backend -> root
        root_env = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')
        load_dotenv(root_env)
        
        self.api_key = os.getenv("GROQ_API_KEY")
        if not self.api_key:
            print(f"Warning: GROQ_API_KEY is not set. Tried loading from: {root_env}")
            self.client = None
        else:
            self.client = groq.Groq(api_key=self.api_key)

        # Priority List (User Defined)
        self.models = [
            "openai/gpt-oss-120b",        # 1. 1st Priority
            "llama-3.3-70b-versatile",    # 2. 2nd Priority
            "qwen/qwen3-32b",             # 3. 3rd Priority
            "llama-3.1-8b-instant"        # 4. Ultimate Fallback (added for safety)
        ]

    def analyze_code(self, code: str, context: str = "") -> Dict[str, Any]:
        if not self.client:
            return {
                "error": "GROQ_API_KEY is missing. Please set it in .env file.",
                "analysis": "AI Analysis is disabled."
            }

        system_prompt = (
            "ë‹¹ì‹ ì€ CTF/Wargame ë¬¸ì œ í’€ì´ ë° ì›¹ í•´í‚¹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
            "ì£¼ì–´ì§„ ì½”ë“œì™€ í”„ë¡œì íŠ¸ ì „ì²´ ë§¥ë½(Context)ì„ ë¶„ì„í•˜ì—¬ ë³´ì•ˆ ì·¨ì•½ì ì„ ì°¾ì•„ë‚´ì„¸ìš”. "
            "ì´ ì½”ë“œëŠ” ì›Œê²Œì„(Wargame) ë¬¸ì œì˜ ì¼ë¶€ì´ë¯€ë¡œ, ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ì™€ Flag íšë“ ê°€ëŠ¥ì„±ì— ì§‘ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
            "ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ Markdown ì‚¬ìš©):\n"
            "1. **ìƒíƒœ**: 'âœ… **ì•ˆì „í•¨**' ë˜ëŠ” 'ğŸš¨ **ì·¨ì•½í•¨**' ìœ¼ë¡œ ì‹œì‘.\n"
            "2. **ìš”ì•½**: ì·¨ì•½ì ì— ëŒ€í•œ 1~2ë¬¸ì¥ ìš”ì•½.\n"
            "3. **ìƒì„¸ ë¶„ì„**: ë°œê²¬ëœ ì·¨ì•½ì , ì›ì¸, ê³µê²© ë°©ë²• ë“±ì„ ìƒì„¸íˆ ì„¤ëª….\n"
            "4. **ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ (PoC)**: ê°€ëŠ¥í•˜ë‹¤ë©´ ê³µê²©ì„ ìœ„í•œ í˜ì´ë¡œë“œ ì˜ˆì‹œ í¬í•¨.\n"
            "5. **ëŒ€ì‘ ë°©ì•ˆ**: ì½”ë“œë¥¼ ì–´ë–»ê²Œ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ì§€ ì œì•ˆ.\n\n"
            "ë°˜ë“œì‹œ **í•œêµ­ì–´(Korean)**ë¡œ ë‹µë³€í•˜ì„¸ìš”. "
            "ë‹¨ìˆœí•œ ì½”ë“œ ì„¤ëª…ë³´ë‹¤ëŠ”, í•´ì»¤ì˜ ê´€ì ì—ì„œ ì–´ë–»ê²Œ ì•…ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•˜ì„¸ìš”."
        )

        user_prompt = f"Code to analyze:\n```\n{code}\n```"

        for model in self.models:
            try:
                print(f"Attempting analysis with model: {model}")
                chat_completion = self.client.chat.completions.create(
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    model=model,
                    temperature=0.1,
                    max_tokens=2048,
                )
                
                analysis = chat_completion.choices[0].message.content
                return {
                    "model": model,
                    "analysis": analysis,
                    "success": True
                }

            except groq.RateLimitError as e:
                print(f"Rate limit exceeded for {model}. Falling back...")
                continue
            except groq.NotFoundError as e:
                print(f"Model {model} not found or deprecated. Falling back...")
                continue
            except Exception as e:
                print(f"Error with model {model}: {e}")
                # For other errors, we might want to try next model or fail?
                # Let's try next model just in case it's a specific model outage
                continue

        return {
            "error": "All AI models failed or rate limited.",
            "analysis": "Could not complete analysis due to high traffic.",
            "success": False
        }
